import torch
import torch.nn.functional as F
import torch.nn as nn 

class ContrastiveLoss(nn.Module):
    def __init__(self, batch_size, device='cuda:0', temperature=0.5):
        super(ContrastiveLoss, self).__init__()
        self.batch_size = batch_size
        self.register_buffer("temperature", torch.tensor(temperature).to(device))			
        self.register_buffer("negatives_mask", (~torch.eye(batch_size * 2, batch_size * 2, dtype=bool).to(device)).float())		
    def forward(self, emb_i, emb_j):		
        z_i = F.normalize(emb_i, dim=1)     # (bs, dim)  --->  (bs, dim)
        z_j = F.normalize(emb_j, dim=1)     # (bs, dim)  --->  (bs, dim)
        representations = torch.cat([z_i, z_j], dim=0)          # repre: (2*bs, dim)
        similarity_matrix = F.cosine_similarity(representations.unsqueeze(1), representations.unsqueeze(0), dim=2)      # simi_mat: (2*bs, 2*bs)
        sim_ij = torch.diag(similarity_matrix, self.batch_size)         # bs
        sim_ji = torch.diag(similarity_matrix, -self.batch_size)        # bs
        positives = torch.cat([sim_ij, sim_ji], dim=0)                  # 2*bs
        nominator = torch.exp(positives / self.temperature)             # 2*bs
        denominator = self.negatives_mask * torch.exp(similarity_matrix / self.temperature)             # 2*bs, 2*bs
        loss_partial = -torch.log(nominator / torch.sum(denominator, dim=1))        # 2*bs
        loss = torch.sum(loss_partial) / (2 * self.batch_size)
        return loss


class ContrastiveLossBalanced(nn.Module):
    """
    å¸¦åŠ æƒå¹³è¡¡çš„å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°
    
    å€Ÿé‰´HashNetçš„pairwise_loss_updatedæ€æƒ³ï¼Œå¯¹æ­£è´Ÿæ ·æœ¬å¯¹è¿›è¡ŒåŠ æƒå¹³è¡¡ï¼Œ
    é¿å…æ¨¡å‹å› è´Ÿæ ·æœ¬è¿‡å¤šè€Œåªå­¦ä¼š"éƒ½ä¸ç›¸ä¼¼"çš„ç­–ç•¥ã€‚
    
    æ ¸å¿ƒæ”¹è¿›ï¼š
    1. è‡ªåŠ¨è®¡ç®—æ­£è´Ÿæ ·æœ¬å¯¹çš„æ•°é‡
    2. ç»™ç¨€æœ‰çš„æ­£æ ·æœ¬å¯¹æ›´å¤§çš„æƒé‡
    3. ç»™å¸¸è§çš„è´Ÿæ ·æœ¬å¯¹è¾ƒå°çš„æƒé‡
    
    è¿™æ ·å¯ä»¥å¼ºåˆ¶æ¨¡å‹æ›´åŠ å…³æ³¨"ä»€ä¹ˆæ˜¯ç›¸ä¼¼çš„"ï¼Œè€Œä¸æ˜¯ç®€å•è®°ä½"å¤§éƒ¨åˆ†éƒ½ä¸ç›¸ä¼¼"ã€‚
    """
    def __init__(self, batch_size, device='cuda:0', temperature=0.5):
        super(ContrastiveLossBalanced, self).__init__()
        self.batch_size = batch_size
        self.device = device
        self.register_buffer("temperature", torch.tensor(temperature).to(device))
        
        # åˆ›å»ºæ­£è´Ÿæ ·æœ¬çš„mask
        # å¯¹äºè·¨æ¨¡æ€æ£€ç´¢ï¼šæ­£æ ·æœ¬æ˜¯å¯¹è§’çº¿ï¼ˆé…å¯¹çš„å›¾æ–‡ï¼‰
        # è´Ÿæ ·æœ¬æ˜¯éå¯¹è§’çº¿ï¼ˆä¸é…å¯¹çš„å›¾æ–‡ï¼‰
        identity = torch.eye(batch_size, dtype=bool).to(device)
        self.register_buffer("positive_mask", identity)  # [bs, bs]
        self.register_buffer("negative_mask", ~identity)  # [bs, bs]
        
    def forward(self, emb_i, emb_j):
        """
        Args:
            emb_i: å›¾åƒåµŒå…¥ [batch_size, dim]
            emb_j: æ–‡æœ¬åµŒå…¥ [batch_size, dim]
        Returns:
            loss: åŠ æƒå¹³è¡¡åçš„å¯¹æ¯”å­¦ä¹ æŸå¤±
        """
        # L2å½’ä¸€åŒ–
        z_i = F.normalize(emb_i, dim=1)  # [bs, dim]
        z_j = F.normalize(emb_j, dim=1)  # [bs, dim]
        
        # è®¡ç®—å›¾åƒ-æ–‡æœ¬çš„ç›¸ä¼¼åº¦çŸ©é˜µ
        # similarity_matrix[i,j] = ç¬¬iä¸ªå›¾åƒä¸ç¬¬jä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦
        similarity_matrix = torch.mm(z_i, z_j.t())  # [bs, bs]
        
        # ğŸ†• è®¡ç®—æ­£è´Ÿæ ·æœ¬å¯¹çš„æ•°é‡
        S1 = self.positive_mask.sum().float()  # æ­£æ ·æœ¬å¯¹æ•°é‡ = batch_size
        S0 = self.negative_mask.sum().float()  # è´Ÿæ ·æœ¬å¯¹æ•°é‡ = batch_size * (batch_size - 1)
        S = S1 + S0  # æ€»æ ·æœ¬å¯¹æ•°é‡ = batch_size^2
        
        # è®¡ç®—ç¼©æ”¾åçš„ç›¸ä¼¼åº¦
        scaled_sim = similarity_matrix / self.temperature  # [bs, bs]
        
        # å¯¹äºæ¯ä¸ªå›¾åƒï¼Œè®¡ç®—ä¸æ‰€æœ‰æ–‡æœ¬çš„InfoNCEæŸå¤±
        # exp_sim[i,j] = exp(sim[i,j] / temp)
        exp_sim = torch.exp(scaled_sim)  # [bs, bs]
        
        # å¯¹äºæ¯ä¸ªå›¾åƒiï¼š
        # - æ­£æ ·æœ¬ï¼šä¸å®ƒé…å¯¹çš„æ–‡æœ¬j=i
        # - è´Ÿæ ·æœ¬ï¼šå…¶ä»–æ‰€æœ‰æ–‡æœ¬jâ‰ i
        # InfoNCE loss = -log(exp(sim[i,i]) / sum_j(exp(sim[i,j])))
        
        # æå–æ­£æ ·æœ¬çš„ç›¸ä¼¼åº¦ï¼ˆå¯¹è§’çº¿å…ƒç´ ï¼‰
        positive_sim = torch.diag(scaled_sim)  # [bs]
        
        # åˆ†æ¯ï¼šæ‰€æœ‰æ ·æœ¬å¯¹çš„exp(similarity)ä¹‹å’Œ
        # denominator[i] = sum_j exp(sim[i,j])
        denominator = exp_sim.sum(dim=1)  # [bs]
        
        # åŸå§‹çš„InfoNCEæŸå¤±ï¼ˆæœªåŠ æƒï¼‰
        # loss[i] = -log(exp(sim[i,i]) / denominator[i])
        #         = -sim[i,i] + log(denominator[i])
        raw_loss = -positive_sim + torch.log(denominator)  # [bs]
        
        # ğŸ†• å…³é”®æ”¹è¿›ï¼šåˆ†åˆ«è®¡ç®—æ­£è´Ÿæ ·æœ¬çš„è´¡çŒ®ï¼Œå¹¶åŠ æƒ
        # å¯¹äºæ¯ä¸ªå›¾åƒiï¼Œåˆ†è§£æŸå¤±ï¼š
        # loss[i] = -log(exp(positive) / (exp(positive) + sum_negative exp))
        #         = -log(1 / (1 + sum_negative exp / exp(positive)))
        #         = log(1 + sum_negative exp / exp(positive))
        
        # ä½†ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬é‡‡ç”¨HashNetçš„åŠ æƒç­–ç•¥ï¼š
        # ç›´æ¥å¯¹æœ€ç»ˆçš„lossåŠ æƒ
        
        # æ–¹æ³•ï¼šè®¡ç®—æ¯ä¸ªæ ·æœ¬å¯¹çš„æŸå¤±è´¡çŒ®ï¼Œç„¶ååˆ†åˆ«å¯¹æ­£è´Ÿæ ·æœ¬åŠ æƒ
        # ä½†åœ¨æ ‡å‡†InfoNCEä¸­ï¼Œè¿™ä¸å¤ªç›´è§‚
        # æ‰€ä»¥æˆ‘ä»¬é‡‡ç”¨å¦ä¸€ç§ç­‰ä»·æ–¹å¼ï¼š
        
        # è®¡ç®—æ­£æ ·æœ¬çš„æŸå¤±è´¡çŒ®ï¼ˆä½¿ç”¨æ­£æ ·æœ¬æƒé‡ï¼‰
        positive_weight = S / S1  # æƒé‡ = æ€»æ•° / æ­£æ ·æœ¬æ•°
        
        # ä¸ºäº†åŠ æƒè´Ÿæ ·æœ¬ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°è®¡ç®—æŸå¤±
        # æ–°çš„æŸå¤± = -log(exp(pos) / (exp(pos) + weighted_sum(exp(neg))))
        
        # è®¡ç®—åŠ æƒåçš„è´Ÿæ ·æœ¬å’Œ
        exp_positive = torch.exp(positive_sim)  # [bs]
        exp_negative_sum = denominator - exp_positive  # [bs] è´Ÿæ ·æœ¬çš„expå’Œ
        
        # åº”ç”¨è´Ÿæ ·æœ¬æƒé‡
        negative_weight = S / S0  # æƒé‡ = æ€»æ•° / è´Ÿæ ·æœ¬æ•°
        weighted_exp_negative = exp_negative_sum * negative_weight
        
        # åŠ æƒåçš„æŸå¤±
        # loss = -log(exp(pos) / (exp(pos) + weighted_exp(neg)))
        weighted_loss = -torch.log(exp_positive / (exp_positive + weighted_exp_negative))
        
        # å†å¯¹æ­£æ ·æœ¬åº”ç”¨é¢å¤–çš„æƒé‡ï¼ˆå› ä¸ºæˆ‘ä»¬å¸Œæœ›æ›´å…³æ³¨æ­£æ ·æœ¬ï¼‰
        final_loss = weighted_loss * positive_weight
        
        # è¿”å›å¹³å‡æŸå¤±
        return final_loss.mean()


class PairwiseLoss(nn.Module):
    """
    ç›´æ¥å€Ÿé‰´HashNetçš„pairwise_loss_updated
    
    è¿™ä¸ªæŸå¤±å‡½æ•°éœ€è¦æ ‡ç­¾ä¿¡æ¯æ¥åˆ¤æ–­æ ·æœ¬å¯¹æ˜¯å¦ç›¸ä¼¼ã€‚
    é€‚ç”¨äºæœ‰ç›‘ç£çš„å“ˆå¸Œå­¦ä¹ åœºæ™¯ã€‚
    """
    def __init__(self, device='cuda:0'):
        super(PairwiseLoss, self).__init__()
        self.device = device
    
    def forward(self, outputs1, outputs2, label1, label2):
        """
        Args:
            outputs1: ç¬¬ä¸€æ‰¹æ ·æœ¬çš„å“ˆå¸Œç /ç‰¹å¾ [batch_size, hash_dim]
            outputs2: ç¬¬äºŒæ‰¹æ ·æœ¬çš„å“ˆå¸Œç /ç‰¹å¾ [batch_size, hash_dim]
            label1: ç¬¬ä¸€æ‰¹æ ·æœ¬çš„æ ‡ç­¾ [batch_size, num_classes]
            label2: ç¬¬äºŒæ‰¹æ ·æœ¬çš„æ ‡ç­¾ [batch_size, num_classes]
        
        Returns:
            loss: åŠ æƒå¹³è¡¡åçš„æˆå¯¹æŸå¤±
        """
        # è®¡ç®—æ ‡ç­¾ç›¸ä¼¼åº¦ï¼šå¦‚æœä¸¤ä¸ªæ ·æœ¬æœ‰å…±åŒçš„æ ‡ç­¾ï¼Œåˆ™ç›¸ä¼¼
        # similarity[i,j] = 1 if label1[i] å’Œ label2[j] æœ‰é‡å ï¼Œå¦åˆ™ä¸º0
        similarity = (torch.mm(label1.float(), label2.float().t()) > 0).float()
        
        # è®¡ç®—å“ˆå¸Œç çš„å†…ç§¯
        dot_product = torch.mm(outputs1, outputs2.t())  # [bs, bs]
        
        # åˆ›å»ºæ­£è´Ÿæ ·æœ¬mask
        mask_positive = similarity > 0
        mask_negative = similarity <= 0
        
        # è®¡ç®—æŸå¤±ï¼ˆä½¿ç”¨log-expæŠ€å·§ä¿è¯æ•°å€¼ç¨³å®šï¼‰
        # loss = log(1 + exp(-|dot_product|)) + max(dot_product, 0) - similarity * dot_product
        exp_loss = (torch.log(1 + torch.exp(-torch.abs(dot_product))) + 
                   torch.max(dot_product, torch.zeros_like(dot_product)) - 
                   similarity * dot_product)
        
        # ğŸ†• åŠ æƒå¹³è¡¡ï¼ˆHashNetçš„æ ¸å¿ƒæ€æƒ³ï¼‰
        S1 = mask_positive.sum().float()  # æ­£æ ·æœ¬å¯¹æ•°é‡
        S0 = mask_negative.sum().float()  # è´Ÿæ ·æœ¬å¯¹æ•°é‡
        S = S1 + S0  # æ€»æ ·æœ¬å¯¹æ•°é‡
        
        # å¯¹æ­£è´Ÿæ ·æœ¬åˆ†åˆ«åŠ æƒ
        weighted_loss = torch.zeros_like(exp_loss)
        weighted_loss[mask_positive] = exp_loss[mask_positive] * (S / S1)
        weighted_loss[mask_negative] = exp_loss[mask_negative] * (S / S0)
        
        # è¿”å›å¹³å‡æŸå¤±
        return weighted_loss.sum() / S

